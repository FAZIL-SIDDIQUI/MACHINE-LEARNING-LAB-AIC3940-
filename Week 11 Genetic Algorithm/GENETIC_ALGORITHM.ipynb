{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1, Best Score: 0.9824561403508771\n",
      "Generation 2, Best Score: 0.9824561403508771\n",
      "Generation 3, Best Score: 0.9824561403508771\n",
      "Generation 4, Best Score: 0.9824561403508771\n",
      "Generation 5, Best Score: 0.9824561403508771\n",
      "Generation 6, Best Score: 0.9824561403508771\n",
      "Generation 7, Best Score: 0.9824561403508771\n",
      "Generation 8, Best Score: 0.9824561403508771\n",
      "Generation 9, Best Score: 0.9824561403508771\n",
      "Generation 10, Best Score: 0.9824561403508771\n",
      "Best Feature Set: [0, 1, 4, 10, 12, 19, 20, 21, 22, 28]\n",
      "Best n_neighbors: 11\n",
      "Best Accuracy: 0.9824561403508771\n",
      "Generation 1: Accuracy 98.25%\n",
      "Generation 2: Accuracy 98.25%\n",
      "Generation 3: Accuracy 98.25%\n",
      "Generation 4: Accuracy 98.25%\n",
      "Generation 5: Accuracy 98.25%\n",
      "Generation 6: Accuracy 98.25%\n",
      "Generation 7: Accuracy 98.25%\n",
      "Generation 8: Accuracy 98.25%\n",
      "Generation 9: Accuracy 98.25%\n",
      "Generation 10: Accuracy 98.25%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Genetic Algorithm Parameters\n",
    "population_size = 20\n",
    "num_generations = 10\n",
    "mutation_rate = 0.1\n",
    "\n",
    "# Manually initialize population\n",
    "def initialize_population():\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        individual = {\n",
    "            \"features\": [random.randint(0, 1) for _ in range(X.shape[1])],   # Binary mask for features\n",
    "            \"n_neighbors\": random.randint(1, 20)                             # Random number of neighbors for KNN\n",
    "        }\n",
    "        population.append(individual)\n",
    "    return population\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Manually compute Euclidean distance\n",
    "def euclidean_distance(x1, x2):\n",
    "    return math.sqrt(sum((a - b) ** 2 for a, b in zip(x1, x2)))\n",
    "\n",
    "# Manual K-Nearest Neighbors\n",
    "def knn_predict(X_train, y_train, X_test, n_neighbors):\n",
    "    predictions = []\n",
    "    for test_sample in X_test:\n",
    "        # Compute distances to all training samples\n",
    "        distances = [(euclidean_distance(test_sample, train_sample), y) \n",
    "                     for train_sample, y in zip(X_train, y_train)]\n",
    "        # Sort by distance and get top n_neighbors\n",
    "        nearest_neighbors = sorted(distances, key=lambda x: x[0])[:n_neighbors]\n",
    "        # Get most common class in neighbors\n",
    "        labels = [label for _, label in nearest_neighbors]\n",
    "        prediction = max(set(labels), key=labels.count)\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "# Manually calculate accuracy\n",
    "def accuracy_manual(y_true, y_pred):\n",
    "    correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "# Fitness function (Manual cross-validation with accuracy calculation)\n",
    "def fitness(individual):\n",
    "    selected_features = [i for i, bit in enumerate(individual[\"features\"]) if bit == 1]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Avoid individuals with no features selected\n",
    "    X_selected = X[:, selected_features]\n",
    "    y_pred = knn_predict(X_train, y_train, X_test, individual[\"n_neighbors\"])\n",
    "    return accuracy_manual(y_test, y_pred)\n",
    "\n",
    "# Selection\n",
    "def select(population):\n",
    "    population.sort(key=lambda ind: fitness(ind), reverse=True)\n",
    "    return population[:population_size//2]   # Top half for breeding\n",
    "\n",
    "# Crossover\n",
    "def crossover(parent1, parent2):\n",
    "    child = {\"features\": [], \"n_neighbors\": 0}\n",
    "    # Uniform crossover for features\n",
    "    for bit1, bit2 in zip(parent1[\"features\"], parent2[\"features\"]):\n",
    "        child[\"features\"].append(bit1 if random.random() > 0.5 else bit2)\n",
    "    # Blend crossover for n_neighbors\n",
    "    child[\"n_neighbors\"] = (parent1[\"n_neighbors\"] + parent2[\"n_neighbors\"]) // 2\n",
    "    return child\n",
    "\n",
    "# Mutation\n",
    "def mutate(individual):\n",
    "    # Mutate features\n",
    "    for i in range(len(individual[\"features\"])):\n",
    "        if random.random() < mutation_rate:\n",
    "            individual[\"features\"][i] = 1 - individual[\"features\"][i]\n",
    "    # Mutate n_neighbors\n",
    "    if random.random() < mutation_rate:\n",
    "        individual[\"n_neighbors\"] = random.randint(1, 20)\n",
    "\n",
    "# Main GA Loop\n",
    "population = initialize_population()\n",
    "best_scores = []\n",
    "\n",
    "for generation in range(num_generations):\n",
    "    # Evaluate fitness\n",
    "    scores = [fitness(ind) for ind in population]\n",
    "    best_scores.append(max(scores))\n",
    "    print(f\"Generation {generation + 1}, Best Score: {max(scores)}\")\n",
    "\n",
    "    # Selection\n",
    "    selected = select(population)\n",
    "\n",
    "    # Create new population with crossover and mutation\n",
    "    next_population = []\n",
    "    while len(next_population) < population_size:\n",
    "        parent1, parent2 = random.sample(selected, 2)\n",
    "        child = crossover(parent1, parent2)\n",
    "        mutate(child)\n",
    "        next_population.append(child)\n",
    "\n",
    "    # Replace population with the new generation\n",
    "    population = next_population\n",
    "\n",
    "# Find best individual\n",
    "best_individual = max(population, key=fitness)\n",
    "print(\"Best Feature Set:\", [i for i, bit in enumerate(best_individual[\"features\"]) if bit == 1])\n",
    "print(\"Best n_neighbors:\", best_individual[\"n_neighbors\"])\n",
    "print(\"Best Accuracy:\", fitness(best_individual))\n",
    "\n",
    "# Plot accuracy progression (requires matplotlib but done manually here for completeness)\n",
    "for i, score in enumerate(best_scores):\n",
    "    print(f\"Generation {i + 1}: Accuracy {score * 100:.2f}%\")\n",
    "    \n",
    "    \n",
    "# Plot accuracy progression\n",
    "plt.plot(best_scores)\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Progression Over Generations\")\n",
    "plt.show()    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
