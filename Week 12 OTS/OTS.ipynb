{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1  X2  Labels\n",
      "0   2   3       1\n",
      "1   3   3       1\n",
      "2   4   4       1\n",
      "3   6   7       2\n",
      "4   7   8       2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List1\n",
    "Name = [2,3,4,6,7,8]\n",
    "\n",
    "# List2\n",
    "Age = [3,3,4,7,8]\n",
    "\n",
    "labels = [1,1,1,2,2]\n",
    "\n",
    "# get the list of tuples from two lists.\n",
    "# and merge them by using zip().\n",
    "list_of_tuples = list(zip(Name, Age,labels))\n",
    "\n",
    "# Assign data to tuples.\n",
    "list_of_tuples\n",
    "\n",
    "df = pd.DataFrame(list_of_tuples,\n",
    "                  columns=['X1', 'X2','Labels'])\n",
    "# Print data.\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1  X2\n",
      "0   2   3\n",
      "1   3   3\n",
      "2   4   4\n",
      "3   6   7\n",
      "4   7   8\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    2\n",
      "4    2\n",
      "Name: Labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.iloc[:, :-1]  # Features (all columns except the last)\n",
    "y = df.iloc[:, -1]   # Target (the last column)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1\n",
      "Name: Labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Normalize features to ensure equal weight in distance calculation\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def euclidean_distance(x1, x2):\n",
    "#     # Calculate the Euclidean distance between two points\n",
    "#     return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "# def most_common_label(arr):\n",
    "#     # Boyer-Moore Voting Algorithm for finding the most common label\n",
    "#     vote = 0\n",
    "#     candidate = None\n",
    "    \n",
    "#     for i in range(len(arr)):\n",
    "#         if vote == 0:\n",
    "#             candidate = arr[i]\n",
    "#             vote = 1\n",
    "#         else:\n",
    "#             if arr[i] == candidate:\n",
    "#                 vote += 1\n",
    "#             else:\n",
    "#                 vote -= 1\n",
    "#     return candidate\n",
    "\n",
    "# def weights(distance):\n",
    "#     # Avoid division by zero by adding a small epsilon\n",
    "#     return 1 / (distance + 1e-5)\n",
    "\n",
    "# def knn_algorithm(X_train, y_train, X_test, k):\n",
    "#     distances = []\n",
    "\n",
    "#     # Step 1: Calculate the distance between X_test and each X_train\n",
    "#     for i in range(len(X_train)):\n",
    "#         distance = euclidean_distance(X_train[i], X_test)\n",
    "#         distances.append((distance, y_train.iloc[i]))\n",
    "    \n",
    "#     print(\"Euclidean distances are:\")\n",
    "#     print(distances)\n",
    "    \n",
    "#     # Step 2: Sort distances by the first element (distance)\n",
    "#     distances.sort(key=lambda x: x[0])\n",
    "    \n",
    "#     # Step 3: Select the k-nearest neighbors\n",
    "#     k_nearest_neighbors = distances[:k]\n",
    "    \n",
    "#     print(\"K-nearest neighbors:\")\n",
    "#     print(k_nearest_neighbors)\n",
    "    \n",
    "#     # Step 4: Extract the labels of the k-nearest neighbors\n",
    "#     K_nearest_label = [label for _, label in k_nearest_neighbors]\n",
    "    \n",
    "#     print(\"K-nearest labels:\")\n",
    "#     print(K_nearest_label)\n",
    "    \n",
    "#     # Step 5: Use the Boyer-Moore Voting Algorithm to find the most common label\n",
    "#     most_common_label_result = most_common_label(K_nearest_label)\n",
    "    \n",
    "#     print(\"Most common label (Boyer-Moore):\")\n",
    "#     print(most_common_label_result)\n",
    "    \n",
    "#     return most_common_label_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    # Calculate the Euclidean distance between two points\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "def weights(distance):\n",
    "    # Avoid division by zero by adding a small epsilon\n",
    "    return 1 / (distance + 1e-5)\n",
    "\n",
    "def weighted_knn_algorithm(X_train, y_train, X_test, k):\n",
    "    distances = []\n",
    "\n",
    "    # Step 1: Calculate the distance between X_test and each X_train\n",
    "    for i in range(len(X_train)):\n",
    "        distance = euclidean_distance(X_train[i], X_test)\n",
    "        distances.append((distance, y_train.iloc[i]))\n",
    "    \n",
    "    print(\"Euclidean distances are:\")\n",
    "    print(distances)\n",
    "    \n",
    "    # Step 2: Sort distances by the first element (distance)\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Step 3: Select the k-nearest neighbors\n",
    "    k_nearest_neighbors = distances[:k]\n",
    "    \n",
    "    # Step 4: Compute weights for the k-nearest neighbors\n",
    "    weights_list = [weights(dist[0]) for dist in k_nearest_neighbors]\n",
    "    \n",
    "    print(\"K-nearest neighbors with weights:\")\n",
    "    print(k_nearest_neighbors)\n",
    "    \n",
    "    # Step 5: Compute weighted votes for each label\n",
    "    weighted_votes = Counter()\n",
    "\n",
    "    for i, (distance, label) in enumerate(k_nearest_neighbors):\n",
    "        weighted_votes[label] += weights_list[i]\n",
    "    \n",
    "    print(\"Weighted votes:\")\n",
    "    print(weighted_votes)\n",
    "    \n",
    "    # Step 6: Find the label with the highest weighted vote\n",
    "    most_common_label_result = weighted_votes.most_common(1)[0][0]\n",
    "    \n",
    "    return most_common_label_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distances are:\n",
      "[(3.2144954460250608, 2), (0.7197016060085817, 1), (0.539163866017192, 1), (2.500528485366859, 2)]\n",
      "K-nearest neighbors with weights:\n",
      "[(0.539163866017192, 1), (0.7197016060085817, 1), (2.500528485366859, 2)]\n",
      "Weighted votes:\n",
      "Counter({1: 3.2441347271158483, 2: 0.39991386089516157})\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    predicted_label = weighted_knn_algorithm(X_train, y_train, X_test[i], 3)\n",
    "    print(predicted_label)\n",
    "    actual_label = y_test.iloc[i]\n",
    "    \n",
    "    if predicted_label == actual_label:\n",
    "        correct_predictions += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correct predictions 1\n",
      "number of total predictions 1\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"number of correct predictions {}\".format(correct_predictions))\n",
    "print(\"number of total predictions {}\".format(len(X_test)))\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = correct_predictions / len(X_test)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Step 5, you are computing weighted votes for each label based on the inverse of the distance (weight). The label that has the highest sum of weights will be selected as the predicted label.\n",
    "\n",
    "Let's break this down with an example:\n",
    "\n",
    "Example Scenario:\n",
    "Suppose we have the following scenario:\n",
    "\n",
    "Test point: X_test\n",
    "Training set: X_train = [[1, 2], [2, 3], [3, 4], [4, 5]]\n",
    "Labels: y_train = [0, 1, 1, 0]\n",
    "Number of neighbors (k): 3\n",
    "After computing distances, the nearest neighbors and their labels are:\n",
    "Neighbor 1: Distance = 0.2, Label = 1\n",
    "Neighbor 2: Distance = 0.5, Label = 0\n",
    "Neighbor 3: Distance = 0.8, Label = 1\n",
    "Step 5: Compute Weighted Votes\n",
    "Weights: You compute the weight for each neighbor as 1 / distance:\n",
    "\n",
    "Weight for Neighbor 1 = 1 / 0.2 = 5\n",
    "Weight for Neighbor 2 = 1 / 0.5 = 2\n",
    "Weight for Neighbor 3 = 1 / 0.8 = 1.25\n",
    "Weighted Votes Calculation: Now, we accumulate the weights for each label:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "weighted_votes = Counter()\n",
    "\n",
    "# For Neighbor 1 (Label = 1):\n",
    "weighted_votes[1] += 5  # So, weighted_votes = {1: 5}\n",
    "\n",
    "# For Neighbor 2 (Label = 0):\n",
    "weighted_votes[0] += 2  # Now, weighted_votes = {1: 5, 0: 2}\n",
    "\n",
    "# For Neighbor 3 (Label = 1):\n",
    "weighted_votes[1] += 1.25  # Now, weighted_votes = {1: 6.25, 0: 2}\n",
    "Now we have the weighted votes:\n",
    "\n",
    "Label 1 has a total weight of 6.25 (from Neighbor 1 and Neighbor 3).\n",
    "Label 0 has a total weight of 2 (from Neighbor 2).\n",
    "Step 6: Find the Label with the Highest Weighted Vote\n",
    "After calculating the total weighted votes, you can now choose the label that has the highest weight sum:\n",
    "\n",
    "In this case, Label 1 has the highest weight (6.25), so it will be the predicted label.\n",
    "In code:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "most_common_label_result = weighted_votes.most_common(1)[0][0]  # Returns label 1\n",
    "So, the predicted label for X_test will be 1, because it received the highest sum of weighted votes.\n",
    "\n",
    "Summary of Steps:\n",
    "Compute the weights for each neighbor (using 1/distance).\n",
    "Accumulate the weights for each label (so labels with closer neighbors get higher weight).\n",
    "Return the label with the highest total weight as the prediction.\n",
    "This method ensures that closer neighbors have a larger influence on the final prediction compared to farther neighbors, making the voting process weighted instead of simple majority voting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
