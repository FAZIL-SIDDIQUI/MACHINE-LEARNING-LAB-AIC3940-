{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Corpus: [['first', 'document'], ['document', 'second', 'document'], ['third', 'one'], ['first', 'document']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "# Assuming `corpus` is a list of documents, each document being a string\n",
    "\n",
    "# Custom stopword list\n",
    "stopwords = set([\"the\", \"is\", \"in\", \"and\", \"to\", \"from\", \"a\", \"for\", \"of\", \"on\", \"at\", \"with\", \"as\", \"by\", \"an\", \"it\", \"this\", \"that\", \"which\", \"be\", \"or\", \"are\", \"we\", \"can\", \"was\", \"but\", \"has\", \"have\", \"not\", \"if\", \"they\", \"their\", \"will\", \"do\", \"my\", \"all\", \"about\"])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenize and remove stopwords, then lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in text.split() if word not in stopwords]\n",
    "    return words\n",
    "\n",
    "# Example corpus (replace this with your 20 Newsgroups data)\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\"\n",
    "]\n",
    "\n",
    "# Preprocess each document\n",
    "preprocessed_corpus = [preprocess(doc) for doc in corpus]\n",
    "print(\"Preprocessed Corpus:\", preprocessed_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Term Matrix:\n",
      "[1, 1, 0, 0, 0]\n",
      "[2, 0, 0, 1, 0]\n",
      "[0, 0, 1, 0, 1]\n",
      "[1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Get all unique terms across the corpus\n",
    "vocab = sorted(set(word for doc in preprocessed_corpus for word in doc))\n",
    "vocab_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "# Initialize the DTM matrix\n",
    "dtm = [[0] * len(vocab) for _ in range(len(preprocessed_corpus))]\n",
    "\n",
    "# Populate the DTM\n",
    "for doc_idx, doc in enumerate(preprocessed_corpus):\n",
    "    word_counts = Counter(doc)\n",
    "    for word, count in word_counts.items():\n",
    "        dtm[doc_idx][vocab_to_index[word]] = count\n",
    "\n",
    "print(\"Document-Term Matrix:\")\n",
    "for row in dtm:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert DTM to a numpy array\n",
    "dtm = np.array(dtm)\n",
    "\n",
    "# Calculate SVD (from scratch approximation)\n",
    "def svd_from_scratch(matrix, num_components):\n",
    "    # Step 1: Compute matrix * matrix.T and matrix.T * matrix\n",
    "    M = np.dot(matrix, matrix.T)\n",
    "    N = np.dot(matrix.T, matrix)\n",
    "    \n",
    "    # Step 2: Eigen decomposition of M and N\n",
    "    eigvals_u, U = np.linalg.eigh(M)\n",
    "    eigvals_v, V = np.linalg.eigh(N)\n",
    "    \n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    idx_u = np.argsort(eigvals_u)[::-1][:num_components]\n",
    "    idx_v = np.argsort(eigvals_v)[::-1][:num_components]\n",
    "    \n",
    "    U = U[:, idx_u]\n",
    "    V = V[:, idx_v]\n",
    "    \n",
    "    # Step 3: Compute singular values (sqrt of top eigenvalues)\n",
    "    singular_values = np.sqrt(eigvals_u[idx_u])\n",
    "    \n",
    "    return U, singular_values, V.T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Topic Matrix:\n",
      " [[-1.23378806e+00  5.82867088e-16 -6.91206939e-01]\n",
      " [-2.08034021e+00 -9.99200722e-16  8.19868656e-01]\n",
      " [-7.53617870e-17 -1.41421356e+00 -1.13315649e-15]\n",
      " [-1.23378806e+00  9.99200722e-16 -6.91206939e-01]]\n",
      "Topic-Word Matrix:\n",
      " [[-0.89907808 -0.33470998  0.         -0.28218405  0.        ]\n",
      " [ 0.          0.          0.70710678  0.          0.70710678]\n",
      " [-0.1580884   0.84929533  0.         -0.50369186  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Choose number of components\n",
    "num_components = 3\n",
    "U, S, Vt = svd_from_scratch(dtm, num_components)\n",
    "\n",
    "# Document-Topic Matrix (U * S)\n",
    "document_topic_matrix = U * S[:num_components]\n",
    "print(\"Document-Topic Matrix:\\n\", document_topic_matrix)\n",
    "\n",
    "# Topic-Word Matrix (Vt)\n",
    "topic_word_matrix = Vt[:num_components, :]\n",
    "print(\"Topic-Word Matrix:\\n\", topic_word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Topic Probabilities:\n",
      " [[ 6.40930527e-01 -3.02788885e-16  3.59069473e-01]\n",
      " [ 1.65044598e+00  7.92719771e-16 -6.50445980e-01]\n",
      " [ 5.32888306e-17  1.00000000e+00  8.01262638e-16]\n",
      " [ 6.40930527e-01 -5.19066660e-16  3.59069473e-01]]\n",
      "Topic-Word Probabilities:\n",
      " [[ 0.59307033  0.22078901 -0.          0.18614066 -0.        ]\n",
      " [ 0.          0.          0.5         0.          0.5       ]\n",
      " [-0.84307033  4.52921099  0.         -2.68614066  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize rows to get probabilities\n",
    "document_topic_probs = document_topic_matrix / document_topic_matrix.sum(axis=1, keepdims=True)\n",
    "topic_word_probs = topic_word_matrix / topic_word_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "print(\"Document-Topic Probabilities:\\n\", document_topic_probs)\n",
    "print(\"Topic-Word Probabilities:\\n\", topic_word_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.54401349e-01,  4.12149270e-16, -5.41774320e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.54401349e-01,  4.12149270e-16, -5.41774320e-01],\n",
       "       [-7.66184591e-01, -7.06541606e-16,  6.42620551e-01],\n",
       "       [-2.77555756e-17, -1.00000000e+00, -8.88178420e-16],\n",
       "       [-4.54401349e-01,  7.06541606e-16, -5.41774320e-01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.71519453, 1.41421356, 1.27582079])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U           -  (4, 3)\n",
      "Sigma       -  (3,)\n",
      "V_transpose -  (3, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"U           - \",U.shape)\n",
    "print(\"Sigma       - \",S.shape)\n",
    "print(\"V_transpose - \",Vt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=list(range(len(S))), y = S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Topic Matrix:\n",
      " [[-1.23378806e+00  5.82867088e-16 -6.91206939e-01             nan]\n",
      " [-2.08034021e+00 -9.99200722e-16  8.19868656e-01             nan]\n",
      " [-7.53617870e-17 -1.41421356e+00 -1.13315649e-15             nan]\n",
      " [-1.23378806e+00  9.99200722e-16 -6.91206939e-01             nan]]\n",
      "Topic-Word Matrix:\n",
      " [[-0.89907808 -0.33470998  0.         -0.28218405  0.        ]\n",
      " [ 0.          0.          0.70710678  0.          0.70710678]\n",
      " [-0.1580884   0.84929533  0.         -0.50369186  0.        ]\n",
      " [-0.         -0.          0.70710678  0.         -0.70710678]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAIZ SIDDIQUI\\AppData\\Local\\Temp\\ipykernel_18276\\3926595217.py:24: RuntimeWarning: invalid value encountered in sqrt\n",
      "  singular_values = np.sqrt(eigvals_u[idx_u])\n"
     ]
    }
   ],
   "source": [
    "# Choose number of components\n",
    "num_components = 4\n",
    "U, S, Vt = svd_from_scratch(dtm, num_components)\n",
    "\n",
    "# Document-Topic Matrix (U * S)\n",
    "document_topic_matrix = U * S[:num_components]\n",
    "print(\"Document-Topic Matrix:\\n\", document_topic_matrix)\n",
    "\n",
    "# Topic-Word Matrix (Vt)\n",
    "topic_word_matrix = Vt[:num_components, :]\n",
    "print(\"Topic-Word Matrix:\\n\", topic_word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Topic Probabilities:\n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Topic-Word Probabilities:\n",
      " [[ 0.59307033  0.22078901 -0.          0.18614066 -0.        ]\n",
      " [ 0.          0.          0.5         0.          0.5       ]\n",
      " [-0.84307033  4.52921099  0.         -2.68614066  0.        ]\n",
      " [        nan         nan         inf         nan        -inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAIZ SIDDIQUI\\AppData\\Local\\Temp\\ipykernel_18276\\1756369894.py:3: RuntimeWarning: divide by zero encountered in divide\n",
      "  topic_word_probs = topic_word_matrix / topic_word_matrix.sum(axis=1, keepdims=True)\n",
      "C:\\Users\\FAIZ SIDDIQUI\\AppData\\Local\\Temp\\ipykernel_18276\\1756369894.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  topic_word_probs = topic_word_matrix / topic_word_matrix.sum(axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "# Normalize rows to get probabilities\n",
    "document_topic_probs = document_topic_matrix / document_topic_matrix.sum(axis=1, keepdims=True)\n",
    "topic_word_probs = topic_word_matrix / topic_word_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "print(\"Document-Topic Probabilities:\\n\", document_topic_probs)\n",
    "print(\"Topic-Word Probabilities:\\n\", topic_word_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Topic Matrix:\n",
      " [[-1.23378806e+00  5.82867088e-16 -6.91206939e-01             nan]\n",
      " [-2.08034021e+00 -9.99200722e-16  8.19868656e-01             nan]\n",
      " [-7.53617870e-17 -1.41421356e+00 -1.13315649e-15             nan]\n",
      " [-1.23378806e+00  9.99200722e-16 -6.91206939e-01             nan]]\n",
      "Topic-Word Matrix:\n",
      " [[-0.89907808 -0.33470998  0.         -0.28218405  0.        ]\n",
      " [ 0.          0.          0.70710678  0.          0.70710678]\n",
      " [-0.1580884   0.84929533  0.         -0.50369186  0.        ]\n",
      " [-0.         -0.          0.70710678  0.         -0.70710678]\n",
      " [-0.40824829  0.40824829  0.          0.81649658  0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAIZ SIDDIQUI\\AppData\\Local\\Temp\\ipykernel_18276\\3926595217.py:24: RuntimeWarning: invalid value encountered in sqrt\n",
      "  singular_values = np.sqrt(eigvals_u[idx_u])\n"
     ]
    }
   ],
   "source": [
    "# Choose number of components\n",
    "num_components = 5\n",
    "U, S, Vt = svd_from_scratch(dtm, num_components)\n",
    "\n",
    "# Document-Topic Matrix (U * S)\n",
    "document_topic_matrix = U * S[:num_components]\n",
    "print(\"Document-Topic Matrix:\\n\", document_topic_matrix)\n",
    "\n",
    "# Topic-Word Matrix (Vt)\n",
    "topic_word_matrix = Vt[:num_components, :]\n",
    "print(\"Topic-Word Matrix:\\n\", topic_word_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Topic Probabilities:\n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Topic-Word Probabilities:\n",
      " [[ 0.59307033  0.22078901 -0.          0.18614066 -0.        ]\n",
      " [ 0.          0.          0.5         0.          0.5       ]\n",
      " [-0.84307033  4.52921099  0.         -2.68614066  0.        ]\n",
      " [        nan         nan         inf         nan        -inf]\n",
      " [-0.5         0.5         0.          1.          0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FAIZ SIDDIQUI\\AppData\\Local\\Temp\\ipykernel_18276\\1756369894.py:3: RuntimeWarning: divide by zero encountered in divide\n",
      "  topic_word_probs = topic_word_matrix / topic_word_matrix.sum(axis=1, keepdims=True)\n",
      "C:\\Users\\FAIZ SIDDIQUI\\AppData\\Local\\Temp\\ipykernel_18276\\1756369894.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  topic_word_probs = topic_word_matrix / topic_word_matrix.sum(axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "# Normalize rows to get probabilities\n",
    "document_topic_probs = document_topic_matrix / document_topic_matrix.sum(axis=1, keepdims=True)\n",
    "topic_word_probs = topic_word_matrix / topic_word_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "print(\"Document-Topic Probabilities:\\n\", document_topic_probs)\n",
    "print(\"Topic-Word Probabilities:\\n\", topic_word_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Lemmatization is the process of reducing words to their base or root form, known as the \"lemma.\" It considers the meaning and context of the word, unlike stemming, which simply chops off word endings. For instance, lemmatization would reduce words like \"running,\" \"ran,\" and \"runs\" to their base form, \"run,\" and \"better\" to \"good,\" if those are their root forms.\n",
    "\n",
    "Lemmatization is especially useful in natural language processing because it ensures that words with similar meanings are treated as the same word, which can improve the quality of text analysis and topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
