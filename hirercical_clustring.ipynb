{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FAIZ SIDDIQUI\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:74: RuntimeWarning: Invalid cache, redownloading file\n",
      "  warn(\"Invalid cache, redownloading file\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load Fashion-MNIST dataset\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m fashion_mnist \u001b[38;5;241m=\u001b[39m fetch_openml(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFashion-MNIST\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m fashion_mnist\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# Normalize the data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Reduce dimensionality for visualization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\FAIZ SIDDIQUI\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\FAIZ SIDDIQUI\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1129\u001b[0m, in \u001b[0;36mfetch_openml\u001b[1;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# obtain the data\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m url \u001b[38;5;241m=\u001b[39m _DATA_FILE\u001b[38;5;241m.\u001b[39mformat(data_description[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m-> 1129\u001b[0m bunch \u001b[38;5;241m=\u001b[39m _download_data_to_bunch(\n\u001b[0;32m   1130\u001b[0m     url,\n\u001b[0;32m   1131\u001b[0m     return_sparse,\n\u001b[0;32m   1132\u001b[0m     data_home,\n\u001b[0;32m   1133\u001b[0m     as_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(as_frame),\n\u001b[0;32m   1134\u001b[0m     openml_columns_info\u001b[38;5;241m=\u001b[39mfeatures_list,\n\u001b[0;32m   1135\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m   1136\u001b[0m     target_columns\u001b[38;5;241m=\u001b[39mtarget_columns,\n\u001b[0;32m   1137\u001b[0m     data_columns\u001b[38;5;241m=\u001b[39mdata_columns,\n\u001b[0;32m   1138\u001b[0m     md5_checksum\u001b[38;5;241m=\u001b[39mdata_description[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmd5_checksum\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1139\u001b[0m     n_retries\u001b[38;5;241m=\u001b[39mn_retries,\n\u001b[0;32m   1140\u001b[0m     delay\u001b[38;5;241m=\u001b[39mdelay,\n\u001b[0;32m   1141\u001b[0m     parser\u001b[38;5;241m=\u001b[39mparser_,\n\u001b[0;32m   1142\u001b[0m     read_csv_kwargs\u001b[38;5;241m=\u001b[39mread_csv_kwargs,\n\u001b[0;32m   1143\u001b[0m )\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_X_y:\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bunch\u001b[38;5;241m.\u001b[39mdata, bunch\u001b[38;5;241m.\u001b[39mtarget\n",
      "File \u001b[1;32mc:\\Users\\FAIZ SIDDIQUI\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:683\u001b[0m, in \u001b[0;36m_download_data_to_bunch\u001b[1;34m(url, sparse, data_home, as_frame, openml_columns_info, data_columns, target_columns, shape, md5_checksum, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParserError\n\u001b[0;32m    681\u001b[0m     no_retry_exception \u001b[38;5;241m=\u001b[39m ParserError\n\u001b[1;32m--> 683\u001b[0m X, y, frame, categories \u001b[38;5;241m=\u001b[39m _retry_with_clean_cache(\n\u001b[0;32m    684\u001b[0m     url, data_home, no_retry_exception\n\u001b[0;32m    685\u001b[0m )(_load_arff_response)(\n\u001b[0;32m    686\u001b[0m     url,\n\u001b[0;32m    687\u001b[0m     data_home,\n\u001b[0;32m    688\u001b[0m     parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    689\u001b[0m     output_type\u001b[38;5;241m=\u001b[39moutput_type,\n\u001b[0;32m    690\u001b[0m     openml_columns_info\u001b[38;5;241m=\u001b[39mfeatures_dict,\n\u001b[0;32m    691\u001b[0m     feature_names_to_select\u001b[38;5;241m=\u001b[39mdata_columns,\n\u001b[0;32m    692\u001b[0m     target_names_to_select\u001b[38;5;241m=\u001b[39mtarget_columns,\n\u001b[0;32m    693\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m    694\u001b[0m     md5_checksum\u001b[38;5;241m=\u001b[39mmd5_checksum,\n\u001b[0;32m    695\u001b[0m     n_retries\u001b[38;5;241m=\u001b[39mn_retries,\n\u001b[0;32m    696\u001b[0m     delay\u001b[38;5;241m=\u001b[39mdelay,\n\u001b[0;32m    697\u001b[0m     read_csv_kwargs\u001b[38;5;241m=\u001b[39mread_csv_kwargs,\n\u001b[0;32m    698\u001b[0m )\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Bunch(\n\u001b[0;32m    701\u001b[0m     data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    702\u001b[0m     target\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    706\u001b[0m     target_names\u001b[38;5;241m=\u001b[39mtarget_columns,\n\u001b[0;32m    707\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\FAIZ SIDDIQUI\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:78\u001b[0m, in \u001b[0;36m_retry_with_clean_cache.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_path):\n\u001b[0;32m     77\u001b[0m     os\u001b[38;5;241m.\u001b[39munlink(local_path)\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\FAIZ SIDDIQUI\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:518\u001b[0m, in \u001b[0;36m_load_arff_response\u001b[1;34m(url, data_home, parser, output_type, openml_columns_info, feature_names_to_select, target_names_to_select, shape, md5_checksum, n_retries, delay, read_csv_kwargs)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_arff_response\u001b[39m(\n\u001b[0;32m    436\u001b[0m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    437\u001b[0m     data_home: Optional[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    447\u001b[0m     read_csv_kwargs: Optional[Dict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    448\u001b[0m ):\n\u001b[0;32m    449\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the ARFF data associated with the OpenML URL.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    In addition of loading the data, this function will also check the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m        `output_array_type == \"pandas\"`.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 518\u001b[0m     gzip_file \u001b[38;5;241m=\u001b[39m _open_openml_url(url, data_home, n_retries\u001b[38;5;241m=\u001b[39mn_retries, delay\u001b[38;5;241m=\u001b[39mdelay)\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m closing(gzip_file):\n\u001b[0;32m    520\u001b[0m         md5 \u001b[38;5;241m=\u001b[39m hashlib\u001b[38;5;241m.\u001b[39mmd5()\n",
      "File \u001b[1;32mc:\\Users\\FAIZ SIDDIQUI\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:182\u001b[0m, in \u001b[0;36m_open_openml_url\u001b[1;34m(openml_path, data_home, n_retries, delay)\u001b[0m\n\u001b[0;32m    180\u001b[0m                 opener \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mGzipFile\n\u001b[0;32m    181\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m opener(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmpdir, file_name), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m--> 182\u001b[0m                 shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(fsrc, fdst)\n\u001b[0;32m    183\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mmove(fdst\u001b[38;5;241m.\u001b[39mname, local_path)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\FAIZ SIDDIQUI\\anaconda3\\Lib\\shutil.py:203\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    201\u001b[0m fsrc_read \u001b[38;5;241m=\u001b[39m fsrc\u001b[38;5;241m.\u001b[39mread\n\u001b[0;32m    202\u001b[0m fdst_write \u001b[38;5;241m=\u001b[39m fdst\u001b[38;5;241m.\u001b[39mwrite\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buf \u001b[38;5;241m:=\u001b[39m fsrc_read(length):\n\u001b[0;32m    204\u001b[0m     fdst_write(buf)\n",
      "File \u001b[1;32mc:\\Users\\FAIZ SIDDIQUI\\anaconda3\\Lib\\http\\client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[1;32m--> 473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_chunked(amt)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\FAIZ SIDDIQUI\\anaconda3\\Lib\\http\\client.py:605\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    603\u001b[0m             amt \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m chunk_left\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(value)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(value)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Fashion-MNIST dataset\n",
    "fashion_mnist = fetch_openml('Fashion-MNIST')\n",
    "X = fashion_mnist.data / 255.0  # Normalize the data\n",
    "\n",
    "# Reduce dimensionality for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_matrix(X):\n",
    "    \"\"\"Compute pairwise Euclidean distance matrix.\"\"\"\n",
    "    num_points = X.shape[0]\n",
    "    distance_matrix = np.zeros((num_points, num_points))\n",
    "    for i in range(num_points):\n",
    "        for j in range(i + 1, num_points):\n",
    "            distance = np.linalg.norm(X[i] - X[j])\n",
    "            distance_matrix[i, j] = distance\n",
    "            distance_matrix[j, i] = distance\n",
    "    return distance_matrix\n",
    "\n",
    "def hierarchical_clustering(X, num_clusters):\n",
    "    \"\"\"Perform agglomerative hierarchical clustering.\"\"\"\n",
    "    clusters = [[i] for i in range(len(X))]\n",
    "    distances = compute_distance_matrix(X)\n",
    "\n",
    "    while len(clusters) > num_clusters:\n",
    "        # Find the two closest clusters\n",
    "        min_distance = float('inf')\n",
    "        merge_idx1, merge_idx2 = -1, -1\n",
    "        for i in range(len(clusters)):\n",
    "            for j in range(i + 1, len(clusters)):\n",
    "                dist = min([distances[p1, p2] for p1 in clusters[i] for p2 in clusters[j]])\n",
    "                if dist < min_distance:\n",
    "                    min_distance = dist\n",
    "                    merge_idx1, merge_idx2 = i, j\n",
    "\n",
    "        # Merge clusters\n",
    "        clusters[merge_idx1].extend(clusters[merge_idx2])\n",
    "        clusters.pop(merge_idx2)\n",
    "\n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_score(X, labels):\n",
    "    # Implement silhouette score calculation\n",
    "    pass  # Pseudocode for silhouette score\n",
    "\n",
    "def davies_bouldin_index(X, labels):\n",
    "    # Implement Davies-Bouldin Index calculation\n",
    "    pass  # Pseudocode for Davies-Bouldin Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "def plot_clusters(X, labels):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"Clusters Visualization\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_dendrogram(X):\n",
    "    # Generate dendrogram from hierarchical clusters\n",
    "    dendrogram(X)\n",
    "    plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "    plt.xlabel(\"Sample index\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
